{
  "attention": {
    "window_size": 7
  },
  "batch_size": 128,
  "epochs": 50,
  "gradient_clipping": true,
  "name": "m8",
  "optimizer": {
    "learning_rate": 0.001,
    "type": "Adam",
    "weight_decay": 0
  },
  "rnn": {
    "dropout": 0.1,
    "hidden_size": 256,
    "num_layers": 2
  },
  "source_vocabulary_size": 20000,
  "target_vocabulary_size": 20000,
  "teacher_forcing": 0,
  "training": {
    "eval_every": 500,
    "sample_every": 500
  }
}
