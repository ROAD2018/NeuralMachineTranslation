{
  "attention": {
    "enabled": false,
    "window_size": 7
  },
  "batch_size": 128,
  "epochs": 50,
  "gradient_clipping": false,
  "input_feeding": true,
  "name": "without-attention-2",
  "optimizer": {
    "learning_rate": 0.003,
    "type": "Adam",
    "weight_decay": 0
  },
  "rnn": {
    "dropout": 0,
    "hidden_size": 256,
    "num_layers": 2
  },
  "source_vocabulary_size": 25000,
  "target_vocabulary_size": 25000,
  "teacher_forcing": 1,
  "training": {
    "eval_every": 500,
    "sample_every": 500
  }
}
